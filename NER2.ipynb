{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a513f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f5399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063ad442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from termcolor import colored\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce04592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model from local directory\n",
    "model_dir = r\"E:\\NER_model\"  # Replace with the actual path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f95d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8ac788",
   "metadata": {},
   "outputs": [],
   "source": [
    "nationalities_lst = ['مصر','فلسطين','اسرائيل','امريكي', 'أفغاني', 'ألباني', 'جزائري', 'أرجنتيني', 'أرميني', 'أسترالي', 'نمساوي', 'أذربيجاني', 'بحريني', 'بنغلاديشي', 'بيلاروسي', 'بلجيكي', 'بوليفي', 'بوسني', 'برازيلي', 'بلغاري', 'كندي', 'تشيلي', 'صيني', 'كولومبي', 'كوستاريكي', 'كرواتي', 'كوبي', 'تشيكي', 'دنماركي', 'دومينيكاني', 'هولندي', 'إكوادوري', 'مصري', 'سلفادوري', 'إماراتي', 'استوني', 'إثيوبي', 'فنلندي', 'فرنسي', 'جورجي', 'ألماني', 'غاني', 'يوناني', 'غواتيمالي', 'هايتي', 'هندوراسي', 'هنغاري', 'أيسلندي', 'هندي', 'إندونيسي', 'إيراني', 'عراقي', 'أيرلندي', 'إسرائيلي', 'إيطالي', 'جامايكي', 'ياباني', 'أردني', 'كازاخستاني', 'كيني', 'كويتي', 'قيرغيزستاني', 'لاتفي', 'لبناني', 'ليبي', 'ليتواني', 'لوكسمبورغي', 'مقدوني', 'ماليزي', 'مالطي', 'مكسيكي', 'مولدوفي', 'منغولي', 'مونتينيغرين', 'مغربي', 'ناميبي', 'نيبالي', 'نيوزيلندي', 'نيكاراغواي', 'نيجيري', 'نرويجي', 'عماني', 'باكستاني', 'بنمي', 'باراغواي', 'بيروفي', 'فلبيني', 'بولندي', 'برتغالي', 'قطري', 'روماني', 'روسي', 'سعودي', 'صربي', 'سنغافوري', 'سلوفاكي', 'سلوفيني', 'صومالي', 'جنوب أفريقي', 'اوكراني', 'اميركي']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82c4442",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['فلسطين', 'افغانستان', 'البانيا', 'الجزائر', 'اندورا', 'انغولا', 'انتيغوا وبربودا', 'الارجنتين', 'ارمينيا', 'استراليا', 'النمسا', 'اذربيجان', 'الباهاما', 'البحرين', 'بنغلاديش', 'بربادوس', 'بيلاروسيا', 'بلجيكا', 'بليز', 'بنين', 'بوتان', 'بوليفيا', 'البوسنة والهرسك', 'بوتسوانا', 'البرازيل', 'بروناي', 'بلغاريا', 'بوركينا فاسو', 'بوروندي', 'كابو فيردي', 'كمبوديا', 'الكاميرون', 'كندا', 'جمهورية افريقيا الوسطى', 'تشاد', 'تشيلي', 'الصين', 'كولومبيا', 'جزر القمر', 'جمهورية الكونغو', 'كوستا ريكا', 'كرواتيا', 'كوبا', 'قبرص', 'تشيكيا', 'الدنمارك', 'جيبوتي', 'دومينيكا', 'جمهورية الدومينيكان', 'تيمور الشرقية (تيمور الشرقية)', 'الاكوادور', 'مصر', 'السلفادور', 'غينيا الاستوائية', 'اريتريا', 'استونيا', 'اسواتيني (سابقًا \"سوازيلاند\")', 'اثيوبيا', 'فيجي', 'فنلندا', 'فرنسا', 'الغابون', 'غامبيا', 'جورجيا', 'المانيا', 'غانا', 'اليونان', 'غرينادا', 'غواتيمالا', 'غينيا', 'غينيا بيساو', 'غيانا', 'هايتي', 'هندوراس', 'هنغاريا', 'آيسلندا', 'الهند', 'اندونيسيا', 'ايران', 'العراق', 'ايرلندا', 'اسرائيل', 'ايطاليا', 'جامايكا', 'اليابان', 'الاردن', 'كازاخستان', 'كينيا', 'كيريباتي', 'كوريا، الشمالية', 'كوريا، الجنوبية', 'كوسوفو', 'الكويت', 'قيرغيزستان', 'لاوس', 'لاتفيا', 'لبنان', 'ليسوتو', 'ليبريا', 'ليبيا', 'ليختنشتاين', 'ليتوانيا', 'لوكسمبورغ', 'مدغشقر', 'مالاوي', 'ماليزيا', 'المالديف', 'مالي', 'مالطا', 'جزر مارشال', 'موريتانيا', 'موريشيوس', 'المكسيك', 'ميكرونيزيا', 'مولدوفا', 'موناكو', 'منغوليا', 'الجبل الاسود', 'المغرب', 'موزمبيق', 'ميانمار (بورما)', 'ناميبيا', 'ناورو', 'نيبال', 'هولندا', 'نيوزيلندا', 'نيكاراغوا', 'النيجر', 'نيجيريا', 'شمال مقدونيا (سابقًا \"مقدونيا\")', 'النرويج', 'عمان', 'باكستان', 'بالاو', 'بنما', 'بابوا غينيا الجديدة', 'باراغواي', 'بيرو', 'الفلبين', 'بولندا', 'البرتغال', 'قطر', 'رومانيا', 'روسيا', 'رواندا', 'سانت كيتس ونيفيس', 'سانت لوسيا', 'سانت فينسنت والغرينادين', 'ساموا', 'سان مارينو', 'ساو تومي وبرينسيبي', 'المملكة العربية السعودية', 'السنغال', 'صربيا', 'سيشيل', 'سيراليون', 'سنغافورة', 'سلوفاكيا', 'سلوفينيا', 'جزر سليمان', 'الصومال', 'جنوب افريقيا', 'جنوب السودان', 'اسبانيا', 'سريلانكا', 'السودان', 'سوريا', 'تايوان', 'طاجيكستان', 'تنزانيا', 'تايلاند', 'توغو', 'تونجا', 'ترينيداد وتوباغو', 'تونس', 'تركيا', 'تركمانستان', 'توفالو', 'اوغندا', 'اوكرانيا', 'الامارات العربية المتحدة', 'المملكة المتحدة', 'الولايات المتحدة', 'اوروغواي', 'اوزبكستان', 'فانواتو', 'الفاتيكان', 'فنزويلا', 'فيتنام', 'اليمن', 'زامبيا', 'زيمبابوي', 'اسرائيل', 'السعودية']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6df69e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"أكد وزير الخارجية السعودي، اليوم السبت، أن الأحداث المأساوية في فلسطين تحتم علينا التحرك العاجل لوقف إطلاق النار، معلناً رفض بلاده بشكل قاطع تهجير الفلسطينيين من أراضيهم. وطالب خلال كلمته في قمة السلام بالقاهرة بفتح فوري لممرات إنسانية آمنة إلى غزة، داعياً المجتمع الدولي إلى إلزام إسرائيل بالتقيد بالقانون الدولي. وقال خلال مشاركته في القمة: «نرفض محاولات التهجير القسري للفلسطينيين، وإننا نعرب عن خيبة أملنا في عجز مجلس الأمن الدولي عن اتخاذ موقف حيال الأزمة الحالية في غزة حتى الآن، ونطالب بفتح فوري لممرات إنسانية آمنة». وعبر وزير الخارجية السعودية عن أمله في أن تسهم هذه القمة في تحرك حاسم للمجتمع الدولي لإيجاد حل لهذه الأزمة، مؤكداً على «تمسك المملكة بالسلام خياراً استراتيجياً عبر الوقوف مع الشعب الفلسطيني لاستعادة حقوقه المشروعة». وقدم وزير الخارجية السعودي الشكر للرئيس المصري عبد الفتاح السيسي، وحكومة مصر، على الجهود المبذولة «لتعزيز التنسيق والتشاور الإقليمي والدولي تجاه ما نشهده من تطورات خطيرة في قطاع غزة». كان الأمير فيصل بن فرحان بن عبد الله وزير الخارجية السعودي، وصل اليوم إلى العاصمة المصرية القاهرة، لترؤس وفد المملكة المشارك في قمة القاهرة للسلام، والمنعقدة بشأن مناقشة الصراع في غزة ومحيطها، ومستقبل القضية الفلسطينية، وذلك نيابةً عن الأمير محمد بن سلمان بن عبد العزيز ولي العهد رئيس مجلس الوزراء كما شارك بوتين. ويشارك في القمة عدد من الدول والمنظمات الدولية لبحث تطورات الأوضاع الراهنة في فلسطين، والعمل على حماية المدنيين في قطاع غزة المُحاصر، والسماح بفتح ممرات آمنة، وإدخال المساعدات الإنسانية والطبية والغذائية\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87849ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "كما أعلن الجيش الإسرائيلي أن القاعدة تعرضت لهجوم جوي من دون وقوع أضرار أو إصابات\n",
    "\n",
    "وقيل إن الطويل قتل الإثنين في هجوم إسرائيلي بقرية في لبنان.\n",
    "\n",
    "وجاء اغتيال الطويل في أعقاب مقتل العاروري، الأسبوع الماضي، في غارة جوية إسرائيلية على معقل الحزب في العاصمة اللبنانية بيروت.\n",
    "\n",
    "وفي أعقاب استهداف العاروري، ذكر الأمين العام حسن نصر الله أن الرد على استهداف العاروري آت لا محالة\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a013b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_named_entities(text):\n",
    "    # Perform NER on the text\n",
    "    results = ner_pipeline(text)\n",
    "\n",
    "    # Store named entities in a list of dictionaries\n",
    "    named_entities = []\n",
    "\n",
    "    for result in results:\n",
    "        entity_info = {\n",
    "            \"Entity\": result['word'],\n",
    "            \"Label\": result['entity'],\n",
    "        }\n",
    "        named_entities.append(entity_info)\n",
    "        \n",
    "    return named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e4eb5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_combined_results(named_entities):\n",
    "    combined_results = []\n",
    "    current_entity = {\"word\": \"\", \"label\": \"\"}\n",
    "\n",
    "    for result in named_entities:\n",
    "        entity_word = result[\"Entity\"]\n",
    "        label = result[\"Label\"]\n",
    "\n",
    "        # Check if the token starts with \"##\" and append it to the previous word\n",
    "        if entity_word.startswith(\"##\"):\n",
    "            current_entity[\"word\"] += entity_word[2:]\n",
    "        else:\n",
    "            # Non-continuation token, add the current entity to the results\n",
    "            if current_entity[\"word\"]:\n",
    "                combined_results.append(current_entity.copy())\n",
    "                current_entity = {\"word\": \"\", \"label\": \"\"}\n",
    "\n",
    "            current_entity[\"word\"] = entity_word\n",
    "            current_entity[\"label\"] = label\n",
    "\n",
    "    # Add the last entity to the results if any\n",
    "    if current_entity[\"word\"]:\n",
    "        combined_results.append(current_entity.copy())\n",
    "        \n",
    "    return combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bc83c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_combined_results(combined_results):\n",
    "    # Iterate through the combined_results and modify as needed\n",
    "    i = 0\n",
    "    while i < len(combined_results) - 1:\n",
    "        current_word = combined_results[i][\"word\"]\n",
    "        next_word = combined_results[i + 1][\"word\"]\n",
    "\n",
    "        # Check if the current word is \"قطاع\" and the next word is \"غزة\"\n",
    "        if current_word == \"قطاع\" and next_word == \"غزة\":\n",
    "            combined_results[i][\"word\"] = f\"{current_word} {next_word}\"\n",
    "            combined_results.pop(i + 1)\n",
    "        else:\n",
    "            i += 1\n",
    "            \n",
    "    return combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9118f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_result_list(combined_results):\n",
    "    # Create a list to store dictionaries\n",
    "    result_list = []\n",
    "\n",
    "    # Create a set to keep track of unique values\n",
    "    unique_values = set()\n",
    "\n",
    "    # Populate the list of dictionaries based on labels\n",
    "    for result in combined_results:\n",
    "        # Replace \"اسراييل\" with \"اسرائيل\"\n",
    "        result_word = result['word'].replace('اسراييل', 'اسرائيل')\n",
    "\n",
    "        if result['label'] == 'B-LOCATION':\n",
    "            label, word = 'مدينة', result_word\n",
    "        elif result['label'] == 'B-ORGANIZATION':\n",
    "            label, word = 'دولة', result_word\n",
    "        else:\n",
    "            continue  # Skip other labels\n",
    "\n",
    "        # Check for uniqueness before adding to the list\n",
    "        if word not in unique_values:\n",
    "            result_list.append({label: word})\n",
    "            unique_values.add(word)\n",
    "        \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e2e8c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_matched_nationalities(text, nationalities_lst):\n",
    "    matched_nationalities = set()\n",
    "\n",
    "    # Replace \"أ\" with \"ا\"\n",
    "    text = text.replace(\"أ\", \"ا\")\n",
    "\n",
    "    # Replace \"إ\" with \"ا\"\n",
    "    text = text.replace(\"إ\", \"ا\")\n",
    "\n",
    "    # Define the part of the word you want to search for\n",
    "    for element in nationalities_lst:\n",
    "        search_part = element\n",
    "\n",
    "        # Create a regex pattern to find the search part\n",
    "        pattern = re.compile(r\"\\b\\w*\" + re.escape(search_part) + r\"\\w*\\b\")\n",
    "\n",
    "        # Find all the matched words in the sentence\n",
    "        matched_words = re.findall(pattern, text)\n",
    "\n",
    "        # Check if any words are found\n",
    "        if matched_words:\n",
    "            matched_nationalities.update(matched_words)\n",
    "\n",
    "    # Convert unique words to dictionaries\n",
    "    result = [{\"جنسية\": word} for word in matched_nationalities]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e063f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def return_persons_names(combined_results):\n",
    "#     persons_set = set()\n",
    "\n",
    "#     current_person = {\"اسم\": \"\"}\n",
    "\n",
    "#     for entity in combined_results:\n",
    "#         if entity['label'] == 'B-PERSON' or entity['label'] == 'I-PERSON':\n",
    "#             current_person[\"اسم\"] += entity['word'] + \" \"\n",
    "#         elif current_person[\"اسم\"]:\n",
    "#             # Remove the trailing space\n",
    "#             current_person[\"اسم\"] = current_person[\"اسم\"].rstrip()\n",
    "\n",
    "#             # Add the current person to the set\n",
    "#             persons_set.add(current_person[\"اسم\"])\n",
    "#             current_person = {\"اسم\": \"\"}\n",
    "\n",
    "#     # Add the last person if any\n",
    "#     if current_person[\"اسم\"]:\n",
    "#         persons_set.add(current_person[\"اسم\"])\n",
    "\n",
    "#     # Convert unique names to dictionaries\n",
    "#     result = [{\"اسم\": name} for name in persons_set]\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3517c3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_indices(text, combined_results):\n",
    "    lst =[]\n",
    "    for i in combined_results:\n",
    "        if i[\"label\"] == \"I-PERSON\" or i[\"label\"]==\"B-PERSON\":\n",
    "            lst.append(i[\"word\"])\n",
    "    # Using regular expression to find all words in the Arabic text\n",
    "    words_in_text = re.findall(r'\\b\\w+\\b', text, flags=re.UNICODE)\n",
    "\n",
    "    # Create a dictionary to store indices for each word\n",
    "    result_dict = {}\n",
    "\n",
    "    # Iterate through the words list and create a dictionary for each word\n",
    "    for target_word in lst:\n",
    "        target_indices = [index for index, word in enumerate(words_in_text) if word == target_word]\n",
    "\n",
    "        if target_indices:\n",
    "            result_dict[target_word] = target_indices\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76fe48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_names(result):\n",
    "    # Flatten the list of indices for each word\n",
    "    flattened_indices = [(word, index) for word, indices in result.items() for index in indices]\n",
    "\n",
    "    # Sort the flattened list by the index\n",
    "    sorted_flattened_indices = sorted(flattened_indices, key=lambda x: x[1])\n",
    "\n",
    "    # Join consecutive words\n",
    "    result_list = []\n",
    "    current_words = None\n",
    "\n",
    "    for word, index in sorted_flattened_indices:\n",
    "        if current_words is None or index == current_words[-1][1] + 1:\n",
    "            if current_words is None:\n",
    "                current_words = [(word, index)]\n",
    "            else:\n",
    "                current_words.append((word, index))\n",
    "        else:\n",
    "            result_list.append(current_words)\n",
    "            current_words = [(word, index)]\n",
    "\n",
    "    # Add the last set of words to the result_list\n",
    "    if current_words is not None:\n",
    "        result_list.append(current_words)\n",
    "\n",
    "    # Create the final list of dictionaries with only joined words\n",
    "    final_result_list = [{'اسم': ' '.join([word for word, _ in words])} for words in result_list]\n",
    "    return final_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "367970c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dates(text):\n",
    "    # Define a regex pattern for the date format with a single slash\n",
    "    pattern = re.compile(r'\\b(\\d{1,2})\\\\(\\d{1,2})\\\\(\\d{4})\\b')\n",
    "\n",
    "    # Find all matches in the text\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    # Format the matches as \"١٠\\١٠\\٢٠٢٣\"\n",
    "    formatted_dates = [f\"{day}\\\\{month}\\\\{year}\" for day, month, year in matches]\n",
    "\n",
    "    # Return unique dates as a list of dictionaries\n",
    "    unique_dates = [{\"تاريخ\": date} for date in set(formatted_dates)]\n",
    "\n",
    "    return unique_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4008835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_some_countries(countries, output):\n",
    "    for entry in output:\n",
    "        if entry.get('جنسية') in countries:\n",
    "            entry['دولة'] = entry.pop('جنسية')\n",
    "        if entry.get('مدينة') in countries:\n",
    "            entry['دولة'] = entry.pop('مدينة')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84ca5fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_unique_results(modified_results):\n",
    "    # Convert each dictionary to a frozenset and store them in a set\n",
    "    unique_set = {frozenset(entry.items()) for entry in modified_results}\n",
    "\n",
    "    # Convert frozensets back to dictionaries and create a list\n",
    "    unique_dicts = [dict(entry_set) for entry_set in unique_set]\n",
    "    \n",
    "    return unique_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50ea71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def return_output(text, nationalities_lst, countries):\n",
    "#     named_entities = return_named_entities(text)\n",
    "#     combined_results = return_combined_results(named_entities)\n",
    "#     combined_results = modify_combined_results(combined_results)\n",
    "#     result_list = return_result_list(combined_results)\n",
    "#     matched_nationalities = return_matched_nationalities(text, nationalities_lst)\n",
    "#     names = return_persons_names(combined_results)\n",
    "#     dates = extract_dates(text)\n",
    "#     output = dates + names + matched_nationalities + result_list\n",
    "#     modifies_results = modify_some_countries(countries, output)\n",
    "#     unique_results = return_unique_results(modifies_results)\n",
    "#     return unique_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f8e7609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_output(text, nationalities_lst, countries):\n",
    "    named_entities = return_named_entities(text)\n",
    "    combined_results = return_combined_results(named_entities)\n",
    "    combined_results = modify_combined_results(combined_results)\n",
    "    result_list = return_result_list(combined_results)\n",
    "    matched_nationalities = return_matched_nationalities(text, nationalities_lst)\n",
    "    dates = extract_dates(text)\n",
    "    result = get_words_indices(text, combined_results)\n",
    "    names = return_names(result)\n",
    "    output = dates + names + matched_nationalities + result_list\n",
    "    modifies_results = modify_some_countries(countries, output)\n",
    "    unique_results = return_unique_results(modifies_results)\n",
    "    return unique_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "998818fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'مدينة': 'بالقاهرة'},\n",
       " {'جنسية': 'للفلسطينيين'},\n",
       " {'دولة': 'مصر'},\n",
       " {'اسم': 'عبد الفتاح السيسي'},\n",
       " {'جنسية': 'الفلسطينيين'},\n",
       " {'دولة': 'مجلس'},\n",
       " {'مدينة': 'القاهرة'},\n",
       " {'دولة': 'السعودية'},\n",
       " {'مدينة': 'غزة'},\n",
       " {'اسم': 'بوتين'},\n",
       " {'دولة': 'المملكة'},\n",
       " {'جنسية': 'المصرية'},\n",
       " {'اسم': 'محمد بن سلمان بن عبد العزيز'},\n",
       " {'دولة': 'اسرائيل'},\n",
       " {'دولة': 'وحكومة'},\n",
       " {'دولة': 'فلسطين'},\n",
       " {'جنسية': 'الفلسطينية'},\n",
       " {'جنسية': 'المصري'},\n",
       " {'جنسية': 'الفلسطيني'},\n",
       " {'مدينة': 'قطاع غزة'},\n",
       " {'اسم': 'فيصل بن فرحان بن عبد الله'},\n",
       " {'جنسية': 'السعودي'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = return_output(text, nationalities_lst, countries)\n",
    "results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69dc6251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'جنسية': 'اسرائيلية'},\n",
       " {'دولة': 'الجيش'},\n",
       " {'اسم': 'الطويل'},\n",
       " {'جنسية': 'اسرائيلي'},\n",
       " {'جنسية': 'الاسرائيلي'},\n",
       " {'دولة': 'لبنان'},\n",
       " {'اسم': 'العاروري'},\n",
       " {'جنسية': 'اللبنانية'},\n",
       " {'مدينة': 'بيروت'},\n",
       " {'اسم': 'حسن نصر الله'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = return_output(text, nationalities_lst, countries)\n",
    "results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b0af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1531f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1133d611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91048ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed8c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43a111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db47a0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45d16a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the Arabic language model for spaCy\n",
    "# nlp = spacy.load(\"xx_ent_wiki_sm\")  # The model for Arabic is \"xx_ent_wiki_sm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64e28137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found: كيف حالك\n",
      "Match found: ما أخبارك\n"
     ]
    }
   ],
   "source": [
    "# # Process the Arabic text\n",
    "# doc = nlp(\"مرحبا، كيف حالك اليوم؟ ما أخبارك؟\")\n",
    "\n",
    "# # Define patterns for matching specific words or phrases\n",
    "# pattern1 = [{\"LOWER\": \"كيف\"}, {\"LOWER\": \"حالك\"}]\n",
    "# pattern2 = [{\"LOWER\": \"ما\"}, {\"LOWER\": \"أخبارك\"}]\n",
    "\n",
    "# # Use spaCy's Matcher to find matches\n",
    "# matcher = spacy.matcher.Matcher(nlp.vocab)\n",
    "# matcher.add(\"سؤال عن الأخبار\", [pattern1])\n",
    "# matcher.add(\"سؤال عن الأخبار\", [pattern2])\n",
    "\n",
    "# # Find matches in the processed document\n",
    "# matches = matcher(doc)\n",
    "\n",
    "# # Print the matches\n",
    "# for match_id, start, end in matches:\n",
    "#     print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b56479ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: كيف حالك , Label: سؤال عن الأخبار\n",
      "Text: ما أخبارك , Label: سؤال عن الأخبار\n"
     ]
    }
   ],
   "source": [
    "# # Print the matches\n",
    "# for match_id, start, end in matches:\n",
    "#     print( \"Text:\", doc[start:end].text, \", Label:\", nlp.vocab.strings[match_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
